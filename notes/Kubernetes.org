* General
- Kubernetes has a cloud provider interface that allows any cloud provider to implement it and integrate Kubernetes seamlessly
- 
* K8S Node
- Each Kubernetes node runs several Kubernetes components, such as a kubelet and a kube proxy. Nodes are managed by a Kubernetes master.
** Node maintenance : done by *Node controller*
- assigns *IP space*
- updates node list with available machines
- monitor health of node
  - unhealthy node gets deleted
  - Pods which were running gets rescheduled to another node
- on adding a new node
  - kubelet try to register itself *self registration*
- new Node object is created
  - metadata
  - labels
- Node condition (Ready, OutOfDisk)
- decommision a node gracefully
  - drain a node ~kubectl dain nodename --grace-period=6000~
** Components
- Proxy: networking
- kubelet: oversees communication with master
* K8S master
[[file:./master-architecture.png]]
** REST / Server
- Provides REST APIs
- Stores the definitions on =etcd=
** etcd
** Scheduler
- Takes care of intiating deployments on nodes
** Controller Manager : Various kinds of controllers
- Node controller
- Replication controller
- ......
** DNS
- as on 1.3, DNS service is part of cluster
* pod basics
- describes app running on container
- 1 or more tightly coupled containers that makes up the app
- Always run on the same machine.
- All containers have same IP and port space
- Apps can communicate with each other using local port numbers
** sample commands run
#+BEGIN_SRC 
kubectl get pod

kubectl describe pod nodehelloworld.example.com

#host port:container port
kubectl port-forward nodehelloworld.example.com 8081:3000
Forwarding from 127.0.0.1:8081 -> 3000
Forwarding from [::1]:8081 -> 3000
Handling connection for 8081

kubectl expose pod nodehelloworld.example.com --type=NodePort --name nodehelloworld-service
service "nodehelloworld-service" exposed

minikube service nodehelloworld-service --url
http://192.168.99.102:31475

kubectl get service

kubectl attach nodehelloworld.example.com
If you don't see a command prompt, try pressing enter.

kubectl exec nodehelloworld.example.com -- ls /app

kubectl describe service nodehelloworld-service
#+END_SRC
** manage a pod
#+BEGIN_SRC 
kubectl create -f ./pod-helloworld.yml

kubectl get pods
#+END_SRC
** useful pod commands
[[file:./podCommands.png]]
* Labels
- key-value pairs similiar to tags in AWS
- can be used to filter using *Label Selectors*
- The label key must adhere to a strict syntax.
  - It has two parts: prefix (optional) and name.
  - If it exists then it is separated from the name by a forward slash (/) and it must be a valid DNS sub-domain.
  - The prefix must be 253 characters long at most
- used on objects ~N X N~ relationship
  - pods
  - nodes
    - tag a node
    - add *nodeSelector* to the pod configuration to run pod only on selected nodes
    - pods will be in *pending state* until matching nodes are available
#+BEGIN_SRC 
kubectl label nodes node1 hardware=high-spec
kubectl label nodes node1 hardware=low-spec

#in pod yml under spec
nodeSelector:
  hardware: high-spec
kubectl get nodes --show-labels
NAME       STATUS    AGE       LABELS
minikube   Ready     50m       beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=minikube

kubectl label nodes minikube hardware=high-spec, application != foo
node "minikube" labeled
#+END_SRC

* Annotations
- Annotations let you associate arbitrary metadata with Kubernetes objects
* scaling
- Replication controllers and replica sets both manage a group of pods identified by a label selector and ensure that a certain number is always up and running
** scaling options
- *stateless* apps can be scaled *horizontally*
- *stateful* can be scaled *vertically*
** can be done using *replication controller*
- enusre specified number of pod replicas are running all the time
- automatic recreation on termination
** commands run
- scale with file
#+BEGIN_SRC 
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl scale --replicas=4 -f ./pod-replication-controller.yml
replicationcontroller "helloworld-controller" scaled
#+END_SRC
- scale using controller name
#+BEGIN_SRC 
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl get rc
NAME                    DESIRED   CURRENT   READY     AGE
helloworld-controller   4         4         4         9m
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl scale --replicas=1 rc/helloworld-controller
replicationcontroller "helloworld-controller" scaled
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl get pods
NAME                               READY     STATUS        RESTARTS   AGE
hello-minikube1-1849020499-71npc   1/1       Running       0          14m
helloworld-controller-2nm50        1/1       Running       0          9m
helloworld-controller-95g66        1/1       Terminating   0          5m
helloworld-controller-b4b7z        1/1       Terminating   0          7m
helloworld-controller-n06pr        1/1       Terminating   0          5m
#+END_SRC
** *Replication set* supports new selector
- selection based on ~filtering~ according to a set of ~values~
- used by ~Deployment Object~
* Services
- _Service is the logical bridge between pods and other services or end-users_
- operates at level 3 (TCP/UDP)
- Pods are very dynamic.They come and go on the kubernetes cluster
  - Replication controller : pods are terminated and created during scaling
  - Deployments : while updating an image version, podsa are terminated and new pods take their place
- =kubectl expose= creates a new service for the pod
- creating a service : creates endpoint for the pod
  - *ClusterIP* : virtual ip address reachable from within the cluster
    - it is dynamic
    - if need static, it should be defined in yml file for service
  - *NodePort* : same on each port that is reachable externally
  - *LoadBalancer* : from *cloud provider* will route external traffic to every node on the NodePort
  - DNS Names
    - *ExternalName* can provide DNS name for the service
    - *DNS add-ons* needs to be enabled

#+BEGIN_SRC 
kubectl create -f service-NodePort.yml
service "helloworld-node-port" created

minikube service helloworld-node-port --url
http://192.168.99.100:31001

http http://192.168.99.100:31001
HTTP/1.1 200 OK

kubectl describe service helloworld-node-port
Name:                   helloworld-node-port
Namespace:              default
Labels:                 <none>
Selector:               app=helloworld
Type:                   NodePort
IP:                     10.0.0.3
Port:                   <unset> 31001/TCP
NodePort:               <unset> 31001/TCP
Endpoints:              172.17.0.4:3000
Session Affinity:       None
No events.
#+END_SRC
* Volumes
** how it works
[[file:./use-volumes.png]]
** for stateful apps
** Persistent Volumes in kubernetes allow to attach volumes to containers that exist even after container is destroyed
** If node stops working, pod is scheduled to another node and same volume is used
- *works only* for nodes in the *same availability zone*
** Aws Ebs example
[[file:./volume-aws-ebs.png]]
** Provisioning
- *AWS Plugin* can provision storage. It create volume before attaching them to a container/node.
- using *StorageClass*
- define storage
  - [[file:./volume-storage-class.png]]
- volume claim
  - [[file:./volume-claim.png]]
- use volume claim in pod
  - [[file:./volume-claim-in-pod.png]]
* StatefulSet
- to manage a distributed data store
- Properties
  - A stable hostname, available in DNS
  - An ordinal index
  - Stable storage linked to the ordinal and hostname
* Secrets
- stored as plaintext in etcd
- distribute *credentials, keys, passwords or secret data* to pods
- used by k8s for internal APIs
- can be used to provide secrets to application
- one can use _other ways_ if not using *Secrets* e.g. /external vault services/
- Usage patterns
  - as *environment variables*
    - [[file:./secrets_env_pod.png]]
  - as a *file* in pod
    - [[file:./secrets_volume_pod.png]]
    - uses *volumes* mounted on container which has *files*
    - *files* can contain *dotenv* or other files based on how secrets are read
  - from *external second image*
** Generation
- using command line
- using yml file
* Namespaces
- allow to create virtual clusters
- logically separate the cluster
- OOB namespaces
  - /default/
  - /kube-system/
- commands
  - =kubectl get namespaces=
  - =kubectl create namespace myspace=
  - set default namespace to launch resources in
    - =export context = $(kubectl config view|awk '/current-context/{print $2}')=
    - =kubectl config set-context $CONTEXT --namespace=myspace=
- Using namespaces to set quotas
  - [[file:./namespace-resource-quotas.png]]  [[file:./namespace-object-quotas.png]]
* Distributed System Design patterns
** Side car pattern
- about co-locating another container in a pod in addition to the main application container.
- e.g. a container to send logs to central logging service
** Ambassador pattern
- representing a remote service as if it were local and possibly enforcing some policy.
- Redis cluster with one master for writes and many replicas for reads.
  - A local ambassador container can serve as a proxy and expose Redis to the main application container on the localhost.
** ADAPTER PATTERN
- standardizing output from the main application container
** Multi-node patterns
- patterns such as leader election, work queues, and scatter-gather are not supported directly,
- but composing pods with standard interfaces to accomplish them is a viable approach with Kubernetes
* APIs
** Kubernetes APIs
** Autoscaling API ~/apis/autoscaling/v1~
** Batch API ~/apis/batch/v1~
* K8S runtimes ~runtime interface~
- ACI (App Container Images) vs OCI (Open Container Initiative)
- Dokcer
                                                         ~-----> runC~
  - ~docker commnand ---> Docker engine -----> containerd -----> runC~
                                                         ~-----> runC~
- Rkt
  - features
    - security and isolation
    - No daemon
    - relies on OS init system
  - App container
  - RKTNETES
* K8S for CI/CD deployment
- a set of steps that a set of changes by developers or operators that modify the code, data or configuration of a system, test them and deploys them to production.
* minikube
** check status of minikube cluster
#+BEGIN_SRC 
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  minikube status
minikubeVM: Stopped
localkube: N/A
#+END_SRC
** start minikube
#+BEGIN_SRC 
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  minikube start
Starting local Kubernetes cluster...
Kubectl is now configured to use the cluster.
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  minikube status
minikubeVM: Running
localkube: Running
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  minikube stop
Stopping local Kubernetes cluster...
Machine stopped.
#+END_SRC
* kubectl
** create deployment
#+BEGIN_SRC 
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  kubectl run hello-minikube1 --image=gcr.io/google_containers/echoserver:1.4 --port=8080
 deployment "hello-minikube1" created
#+END_SRC
** expose deployment
#+BEGIN_SRC 
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  kubectl expose deployment hello-minikube1 --type=NodePort
service "hello-minikube1" exposed
#+END_SRC
** get service url
#+BEGIN_SRC 
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes  minikube service hello-minikube1 --url
http://192.168.99.100:32619
#+END_SRC
* AWS setup
** kops (*Kubernetes Operations*) used for installations, upgrades and management
** Steps on AWS [0/5]
- [-] create a kops user using *IAM*
- [ ] assign administrator policy
- [ ] create a bucket based on region where the cluster is to be installed
- [ ] get a free domain from somewhere
- [ ] use *Amazon Route 53* for DNS
  - [ ] create hosted zone
* architecture
** diagram
[[file:./kubernetes-architecture.png]]
** node architecture
* *Deployment object*
** declaration that allows to do app deployments and updates
** when using ~deployment object~, one can define state of the app
- kubernetes than make sure that the clusters matches your desired state
** with DO, one can
- create
- update
- rolling update
- roll back
- Pause/resume
** commands reference
[[file:./deploymentCommands.png]]
** commands run
#+BEGIN_SRC 
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl get deployments
NAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
hello-minikube1   1         1         1            1           6d
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl get rs
NAME                         DESIRED   CURRENT   READY     AGE
hello-minikube1-1849020499   1         1         1         6d
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code 

gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl rollout status deployment/helloworld-deployment
deployment "helloworld-deployment" successfully rolled out
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl expose deployment helloworld-deployment --type=NodePort
service "helloworld-deployment" exposed
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl get service
NAME                    CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
helloworld-deployment   10.0.0.243   <nodes>       3000:31425/TCP   25s
kubernetes              10.0.0.1     <none>        443/TCP          7d
 gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  kubectl describe service helloworld-deployment
Name:                   helloworld-deployment
Namespace:              default
Labels:                 app=helloworld
Selector:               app=helloworld
Type:                   NodePort
IP:                     10.0.0.243
Port:                   <unset> 3000/TCP
NodePort:               <unset> 31425/TCP
Endpoints:              172.17.0.5:3000,172.17.0.6:3000,172.17.0.7:3000 + 1 more...
Session Affinity:       None
No events.
gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  minikube service helloword-deployment --url
service 'helloword-deployment' could not be found running in namespace 'default' within kubernetes
 ✘ gabbi@Gauravs-Air  ~/learning/udemy/kubernetes/code  minikube service helloworld-deployment --url
http://192.168.99.102:31425
#+END_SRC
** edit deployment
#+BEGIN_SRC 
kubectl edit deployment/healthcheck-deployment
#+END_SRC
- it opens a editor where we can change the settings and save them
- *might not change the actual source file*
* health checks
** to detect application malfunctions
** 2 types
- a periodic command in the container
- periodic checks on the URL (HTTP)
** if failed, pod is terminated and new one is launched
* Web UI
** To access
#+BEGIN_SRC 
minikube dashboard --url
http://192.168.99.100:30000
#+END_SRC
** provides similiar functionality as _kubectl_
** commands
#+BEGIN_SRC sh
  kubectl create -f https://<path to kubernetes-dashboard>

  #to see the password
  kubectl config view
#+END_SRC
* Service Discovery
** DNS is a built-in service since K8s 1.3
[[file:./dns.png]]                      [[file:./dns-internal.png]]   
- can be used to find other services running on same cluster
- to make it work, pod will need a service defintion
- containers in same pod can contact each other using localhost:port. Don't need DNS
- use =nslookup= to get the IP
* configMap
** can be used for non-secret config parameters
** *key-value pairs*
** can be read by the app using
- Environment variables
  - [[file:./configMap-using-env.png]]
- container command line arguments in pod configurations
- volumes
  - [[file:./configMap-specify-in-pod.png]]
- can also contain a full configuration *file* 
  - [[file:./configMap-using-file.png]]
  - file then can be mounted using volumes
** commands
#+BEGIN_SRC sh
  kubectl create configmap nginx-config --from-file=./configMap/reverseproxy.conf

  kubectl get configmap

  kubectl get configmap nginx-config -o yaml
#+END_SRC
* ingress
[[file:./ingress.png]]
** allows *inbound connections* to the cluster
** alternative to load balancer and Node ports
- expose services to be accessed from outside cluster
** run your own *ingress controller*
** default ingress controller or one can write own
* PetSets _Stateful distributed apps on K8s cluster_
** *stable/static Pod hostname*
- podname-0, podname-1
** stateful apps that require multiple volumes based on ordinal number
- deleting/scaling down PetSet will not delete volume
** allow app to use DNS to find other servers
- One running node of a PetSet is called *Pet*
** _order startup and teardown of pets_
* Daemon Sets
** ensure that each node on the cluster runs the same pod resource
** useful when one wants to run certains pods on each node
** node starts, also start the pod
** node stops, do not reschdule the pod on another node
** use cases
- logging aggregators
- monitoring
- load balancers / proxy / api gateway
- any other similiar app per host
** example
[[file:./daemon-set.png]]
* Resource Usage monitoring
** how it works
[[file:./resoure-monitoring.png]]
** Heapster
- enables *Container Cluster Monitoring* *Performance Analysis*
- pre-requisite for *pod auto-scaling*
- export metrics via *REST*
- can be used with differnt backends (InfluxDB, Kafka and others)
- Grafana for view
#+BEGIN_SRC 
minikube service monitoring-grafana --namespace=kube-system --url
http://192.168.99.100:30869
#+END_SRC
- Kubernetes dashboard will also show graphs
* Auto Scaling
** based on metrics *by heapster*
** deployment, replication controller, replica set
** scaling based on CPU is OOB
- also possible for custom metrics
- ENABLE_CUSTOM_METRICS

* Resource Quotas
** control the resources allocated to teams
** deivide cluster into namespaces and assing quotas to it.
** Use objects
- ResoureQuotas
- ObjectQuotas
** container can specify
- request capacity : minimum capacity pod needs
- capacity limits : limits beyond which container cannot utilize resources
** Resource limits that can be set by admin
[[file:./resource-quotas-admin.png]]
** Object quotas that can be set by admin
[[file:./object-quotas-admin.png]]
* User Management
** Normal user
- to connect from external to K8S. e.g. from =kubectl=
- Not managed like K8S object
- Authentication
  - Client certificates
  - Authorization Proxy
  - OpenID
  - HTTP Basic Authentication
  - Bearer Token
  - Webhooks (external service)
- authorization
  - Alwaysallow/AlwaysDeny
  - ABAC (Attribute based access control)
  - RBAC (Role based access control)
  - Webhook
** Service User
- used for internal communication
- managed like K8S objects (secrets)
- Using Service Tokens
- managed using secrets
- specific to namespace
- mounted on the pods
- if call is not from service user, it is considered anonymous call
** Demo
#+BEGIN_SRC sh
  openssl genrsa -out myuser.pem 2048
  openssl req -new -key myuser.pem -out myuser-csr.pem -subj "/CN=myuser/O=myteam/"
  openssl x509 -req -in myuser-csr.pem -CA ~/.minikube/ca.crt -CAkey ~/.minikube/ca.key -CAcreateserial -out myuser.crt -days 10000
#+END_SRC
* Networking
** container to container
- using localhost and the port number
** pod to service
- using NodePort and DNS
** external to service
- using LoadBalancer, NodePort
** pod to pod
- K8S assumes it is always possible, no matter on which node pods are running
- each pod has its own IP address
** set up
|-----+-----------------------------------------------------------------|
| AWS | kubenet                                                         |
|     | - each pod gets ip, that is routable using AWS VPC              |
|     | - k8s master allocates /24 subnet to each node (254 IP addresses) |
|     | - subnet is added to VPC table                                  |
|     | - *50 enteries* limit                                           |
|-----+-----------------------------------------------------------------|
|     | CNI (Container Network Interfaces)                              |
|     | - Calico, Weave                                                 |
|-----+-----------------------------------------------------------------|
|     | An Overlay network                                              |
|     | - Flannel                                                       |
[[file:./flannel.png]]
* HA
[[file:./ha.png]]
- Clustering etcd
- replicated API servers with LoadBalancers
- multiple instances of scheduler and controller
  - only one of them is leader, others are stand-by
** commands
#+BEGIN_SRC sh 
  kops create cluster --name=kubernetes.newtech.academy --state=s3://kops-state-b429b --zones=eu-west-1a --node-count=2 --node-size=t2.micro --master-size=t2.micro --dns-zone=kubernetes.newtech.academy
  kops update cluster kubernetes.newtech.academy --yes --state=s3://kops-state-b429b
  kops delete cluster --name kubernetes.newtech.academy --state=s3://kops-state-b429b
  kops delete cluster --name kubernetes.newtech.academy --state=s3://kops-state-b429b --yes
#+END_SRC
* Istio
[[file:./istio-architecture.png]]
- provides an easy way to create a network of deployed services with
  - load balancing,
  - service-to-service authentication,
  - monitoring, and more,
  - without requiring any changes in service code.
- done by deploying a side-car proxy
  - throughout your environment that intercepts all network communication between microservices, configured and managed using Istio’s control plane functionality.
- *Components*
  - data plane and control plane
  - Envoy : Proxies deployed as sidecars
  - Mixer : Enforcing access control and usage policies and collecting telemetry data
  - Pilot : collecting and validating configuration and propagating it to the various Istio components.
  - Istio-auth : strong service-to-service and end-user authentication using mutual TLS, with built-in identity and credential management
- commands
  - ~kubectl apply -f <(istioctl kube-inject -f uaa/uaa.yml)~
    - injects additional containers into YAML resource on the client before submitting to the Kubernetes API server.
    - This will eventually be replaced by server-side injection via admission controller.
